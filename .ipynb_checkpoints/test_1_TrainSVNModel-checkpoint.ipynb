{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aduarte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\aduarte\\AppData\\Local\\Continuum\\anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:70: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "inicio: 10:37:12\n",
      "[{'_id': ObjectId('5c664129ad907e4b5d6a50be'), 'headline': \"Here's Why The Advertising Industry Needs To Change\", 'body': 'I see something similar happening in the advertising industry. The advertising agencies are the banks. TV networks, Google and Facebook are the young, cocky mortgage brokers. And the business owners are the American people who will end up holding the bag. Iâ€™ve been concerned for a few months, but it really hit me after reading..'}, {'_id': ObjectId('5c664166ad907e4b5d6a50ff'), 'headline': 'The Facebook and Google the Advertising Industries', 'body': 'The Facebook and Google duopoly look to be squeezing their advertisers as much as they can, digging deeper and deeper to get more websites to show ads and people (maybe fake people) to see them'}]\n",
      "fin: 10:37:12\n",
      "                        _id                                               body\n",
      "0  5c664129ad907e4b5d6a50be  I see something similar happening in the adver...\n",
      "1  5c664166ad907e4b5d6a50ff  The Facebook and Google duopoly look to be squ...\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: ariel.duarte\n",
    "\"\"\"\n",
    "import pymongo \n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "from math import log\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('english')\n",
    "import re\n",
    "\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=True, stemmer=True):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "   # review_text = review.replace(\"@\",'')\n",
    "    #review_text = re.sub(r'[^\\w\\s]|\\d','',review)  \n",
    "    \n",
    "   # review = review.lower().split() \n",
    "   \n",
    "   \n",
    "    #pprint(review)\n",
    "    review_text=re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', review) #quita links\n",
    "   \n",
    "    review_text1 = re.sub(r'[^\\w\\s]','',review_text)   #quita caracteres especiales\n",
    "    #pprint(review_text1)\n",
    "    words = review_text1.lower().split() \n",
    " #   wordcloud = review_text.lower().split()\n",
    "\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        stops = list(stops) + ['https', 'co','si']\n",
    "        #stops = list(stops)\n",
    "       # print(stops)\n",
    "        words = [w for w in words if not w in stops]\n",
    "      \n",
    "    if stemmer:\n",
    "        b = []\n",
    "        stemmer = spanish_stemmer\n",
    "        for word in words:\n",
    "            b.append(stemmer.stem(word))\n",
    "    else:\n",
    "        b = words\n",
    "    # 5. Return a list of words\n",
    "    \n",
    "    return(b)\n",
    "\n",
    "def open_conection():\n",
    "    client = pymongo.MongoClient('mongodb://admin:secret@ds143737.mlab.com:43737/springdb')\n",
    "    return client\n",
    "\n",
    "client = open_conection()\n",
    "db = client.springdb\n",
    "col = db.articles\n",
    "\n",
    "print(col.count())\n",
    "print ('inicio:', time.strftime('%H:%M:%S'))\n",
    "#cursor = col.find({'body': \"*/Advertising/*\"},{ 'body': 1, '_id': 1 }) \n",
    "cursor = col.find({'body':{\"$regex\": \".*advertis*\"}})\n",
    "l = list(cursor)\n",
    "tabla = pd.DataFrame(l)\n",
    "print ('fin:', time.strftime('%H:%M:%S'))\n",
    "res = tabla[['_id', 'body']]\n",
    "# print (res)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
